{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab040f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install duckdb --user --pre --upgrade && pip install --pre pandas==2.0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508348c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import boto3\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = \"25GB\" # increase to available python memory -25%\n",
    "TMP_DIR = \"fg-data-v8/\"\n",
    "DUCKDB_FILE = f\"{TMP_DIR}/taxi.duckdb\"\n",
    "DATA_FOLDER = f\"{TMP_DIR}/taxidata\" \n",
    "\n",
    "# S3 Uploads\n",
    "AWS_ACCESS_KEY=''\n",
    "AWS_SECRET_ACCESS_KEY=''\n",
    "AWS_REGION='eu-west-1'\n",
    "BUCKET = \"ayushman-hops\"\n",
    "session = boto3.Session( aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "s3 = session.resource('s3')\n",
    "\n",
    "\n",
    "# HDFS Uploads\n",
    "HOPS_HOST=''\n",
    "HOPS_API_KEY=''\n",
    "HDFS_PATH = \"/Projects/testproj/Resources/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {TMP_DIR}\n",
    "!mkdir -p {DATA_FOLDER}\n",
    "!ls -lR {TMP_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1334ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(DUCKDB_FILE, config={'memory_limit': MAX_MEMORY, 'temp_directory': TMP_DIR}) \n",
    "con.execute(\"INSTALL httpfs;\")\n",
    "con.execute(\"INSTALL parquet;\")\n",
    "con.execute(\"LOAD httpfs;\")\n",
    "con.execute(\"LOAD parquet;\")\n",
    "con.execute(f\"\"\"\n",
    "    SET s3_region='{AWS_REGION}';\n",
    "    SET s3_access_key_id='{AWS_ACCESS_KEY}';\n",
    "    SET s3_secret_access_key='{AWS_SECRET_ACCESS_KEY}';\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a73341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_zone_table():\n",
    "    query = f'''\n",
    "    CREATE OR REPLACE TABLE locations (\n",
    "      LocationID INTEGER,\n",
    "      Borough VARCHAR,\n",
    "      Zone VARCHAR,\n",
    "      service_zone VARCHAR\n",
    "    );\n",
    "\n",
    "    COPY locations FROM 's3://{BUCKET}/taxidata/taxi+_zone_lookup.csv' (FORMAT csv, HEADER true);\n",
    "    '''\n",
    "    con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe8b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_columns(yyyy, mm):\n",
    "    file_path = f's3://{BUCKET}/taxidata/{yyyy}/*{mm}.parquet'\n",
    "    print(f\"Reading {file_path}...\")\n",
    "    con.execute(f\"CREATE OR REPLACE TABLE taxidata AS SELECT * FROM read_parquet('{file_path}');\")\n",
    "    \n",
    "    con.execute(\"ALTER TABLE taxidata ADD COLUMN pu_borough VARCHAR;\")\n",
    "    con.execute(\"ALTER TABLE taxidata ADD COLUMN do_borough VARCHAR;\")\n",
    "    con.execute(\"ALTER TABLE taxidata ADD COLUMN pu_svc_zone VARCHAR;\")\n",
    "    con.execute(\"ALTER TABLE taxidata ADD COLUMN do_svc_zone VARCHAR;\")\n",
    "    con.execute(\"ALTER TABLE taxidata ADD COLUMN pu_zone VARCHAR;\")\n",
    "    con.execute(\"ALTER TABLE taxidata ADD COLUMN do_zone VARCHAR;\")\n",
    "    \n",
    "    # Clean columns\n",
    "    df = con.execute(\"SELECT column_name FROM information_schema.columns WHERE table_name='taxidata'\").df()\n",
    "    # Rename, cast types, and drop columns\n",
    "    column_allow_list = { \n",
    "        # type conversion\n",
    "        \"pickup_datetime\": [\"tpep_pickup_datetime\", \"timestamp\"],\n",
    "        \"tpep_pickup_datetime\": [\"tpep_pickup_datetime\", \"timestamp\"],\n",
    "        \"trip_pickup_datetime\": [\"tpep_pickup_datetime\", \"timestamp\"],\n",
    "\n",
    "        \"dropoff_datetime\": [\"tpep_dropoff_datetime\", \"timestamp\"],\n",
    "        \"tpep_dropoff_datetime\": [\"tpep_dropoff_datetime\", \"timestamp\"],\n",
    "        \"trip_dropoff_datetime\": [\"tpep_dropoff_datetime\", \"timestamp\"],\n",
    "\n",
    "        \"pulocationid\": [\"pu_location_id\", \"integer\"],\n",
    "        \"dolocationid\": [\"do_location_id\", \"integer\"],\n",
    "        \"pu_borough\": [\"pu_borough\", \"varchar\"],\n",
    "        \"pu_svc_zone\": [\"pu_svc_zone\", \"varchar\"],\n",
    "        \"pu_zone\": [\"pu_zone\", \"varchar\"],\n",
    "        \"do_borough\": [\"do_borough\", \"varchar\"],\n",
    "        \"do_svc_zone\": [\"do_svc_zone\", \"varchar\"],\n",
    "        \"do_zone\": [\"do_zone\", \"varchar\"],\n",
    "\n",
    "        \n",
    "        \"pickup_zip\": [\"pickup_zip\", \"integer\"],\n",
    "        \"dropoff_zip\": [\"dropoff_zip\", \"integer\"],\n",
    "        \"trip_distance\": [\"trip_distance\", \"double\"],\n",
    "        \"fare_amount\": [\"fare_amount\", \"double\"],\n",
    "        \"tip_amount\": [\"tip_amount\", \"double\"],\n",
    "        \"fare_amt\": [\"fare_amount\", \"double\"],\n",
    "        \"pickup_latitude\": [\"pickup_latitude\", \"double\"],\n",
    "        \"pickup_longitude\": [\"pickup_longitude\", \"double\"],\n",
    "        \"start_lat\": [\"pickup_latitude\", \"double\"],\n",
    "        \"start_lon\": [\"pickup_longitude\", \"double\"],\n",
    "        \"dropoff_latitude\": [\"dropoff_latitude\", \"double\"],\n",
    "        \"dropoff_longitude\": [\"dropoff_longitude\", \"double\"],\n",
    "        \"end_lat\": [\"dropoff_latitude\", \"double\"],\n",
    "        \"end_lon\": [\"dropoff_longitude\", \"double\"],\n",
    "    }\n",
    "    for val in df.values:\n",
    "        orig = val[0]\n",
    "        orig_lower = orig.lower()\n",
    "        if orig_lower in column_allow_list:\n",
    "            new_name, data_type = column_allow_list[orig_lower]\n",
    "            new_name = new_name.lower()\n",
    "            con.execute(f\"ALTER TABLE taxidata ALTER {orig} TYPE {data_type};\")\n",
    "            con.execute(f\"ALTER TABLE taxidata RENAME {orig} TO {new_name};\")\n",
    "        else:\n",
    "            con.execute(f\"ALTER TABLE taxidata DROP COLUMN {orig}\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_zones():\n",
    "    query = f'''\n",
    "        UPDATE taxidata\n",
    "        SET pu_borough = (\n",
    "            SELECT Borough\n",
    "            FROM locations\n",
    "            WHERE LocationID = taxidata.pu_location_id\n",
    "          ),\n",
    "          do_borough = (\n",
    "            SELECT Borough\n",
    "            FROM locations\n",
    "            WHERE LocationID = taxidata.do_location_id\n",
    "          ),\n",
    "          pu_zone = (\n",
    "            SELECT Zone\n",
    "            FROM locations\n",
    "            WHERE LocationID = taxidata.pu_location_id\n",
    "          ),\n",
    "          do_zone = (\n",
    "            SELECT Zone\n",
    "            FROM locations\n",
    "            WHERE LocationID = taxidata.do_location_id\n",
    "          ),\n",
    "          pu_svc_zone = (\n",
    "            SELECT service_zone\n",
    "            FROM locations\n",
    "            WHERE LocationID = taxidata.pu_location_id\n",
    "          ),\n",
    "          do_svc_zone = (\n",
    "            SELECT service_zone\n",
    "            FROM locations\n",
    "            WHERE LocationID = taxidata.do_location_id\n",
    "          );\n",
    "    '''\n",
    "    con.execute(query)\n",
    "    con.execute(\"ALTER TABLE taxidata DROP pu_location_id;\")\n",
    "    con.execute(\"ALTER TABLE taxidata DROP do_location_id;\")\n",
    "    df = con.execute(\"SELECT * FROM taxidata\").df()\n",
    "    df = df[df.pu_borough != 'Unknown']\n",
    "    df = df[df.do_borough != 'Unknown']\n",
    "    df = df[df.pu_svc_zone != 'N/A']\n",
    "    df = df[df.do_svc_zone != 'N/A']\n",
    "    df = df[df.pu_zone != 'N/A']\n",
    "    df = df[df.do_zone != 'N/A']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab061d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_zone_table()\n",
    "\n",
    "con.execute(\"SELECT * FROM locations LIMIT 4\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2d420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "years = [2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021]\n",
    "\n",
    "for yyyy in years:\n",
    "    for mm in range(1,13):\n",
    "        if mm < 10: mm = f'0{mm}'\n",
    "        get_clean_columns(yyyy, mm)\n",
    "        df = annotate_zones()\n",
    "        print(\"Creating table from df\")\n",
    "        con.execute(\"CREATE OR REPLACE TABLE taxidata as SELECT * FROM df\")\n",
    "        print(f\"Writing local parquet {yyyy}-{mm}\")\n",
    "        con.execute(f\"COPY (SELECT * FROM taxidata) TO '{TMP_DIR}/{yyyy}-{mm}-cleaned.parquet' (FORMAT PARQUET);\")\n",
    "    con.execute(f\"CREATE OR REPLACE TABLE taxidata AS SELECT * FROM read_parquet('{TMP_DIR}/{yyyy}-*.parquet');\")\n",
    "    print(f\"Uploading {yyyy} parquet to S3\")\n",
    "    con.execute(f\"COPY (SELECT * FROM taxidata) TO 's3://{BUCKET}/taxidata_cleaned/{yyyy}.parquet' (FORMAT PARQUET);\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cb91586",
   "metadata": {},
   "source": [
    "### Test reads and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64731545",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = con.execute(f\"CREATE OR REPLACE TABLE taxidata AS SELECT * FROM read_parquet('s3://{BUCKET}/taxidata_cleaned/*.parquet');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"SELECT * FROM read_parquet('s3://{BUCKET}/taxidata_cleaned/2011.parquet') LIMIT 10;\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bdd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"SELECT COUNT(*) FROM read_parquet('s3://{BUCKET}/taxidata_cleaned/*.parquet');\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2656792",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"SELECT COUNT(*) FROM taxidata\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95425f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c424f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
